{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect rings with MRCNN\n",
    "##### Braedyn Au 30/8/19\n",
    "Description\n",
    "\n",
    "Using the trained model, detect, crop, and pad rings out of the image each to 120x120 sizes. Biggest known issue is that the ring center may not align with the center of the image. Further processing in ImageJ may help but due to rings not being perfectly symmetrical, manual editing will probably be unavoidable.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "import os\n",
    "import scipy\n",
    "import numpy as np\n",
    "import skimage.color\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "from skimage.util import pad\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from mrcnn.model import mold_image\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn import visualize as vs\n",
    "#IF WINDOWS OS THEN USE tkinter \n",
    "from tkinter import filedialog, messagebox\n",
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "To change parameters for prediction, same as we did while training. Overwrite original configuration class in config.py. DETECTION_MIN_CONFIDENCE is a parameter you may want to play around with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionConfig(Config):\n",
    "    # define the name of the configuration\n",
    "    NAME = \"Septin_cfg\"\n",
    "    # number of classes (background + Septin)\n",
    "    NUM_CLASSES = 1 + 1\n",
    "    # simplify GPU config\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1   \n",
    "    DETECTION_MIN_CONFIDENCE = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "Now we can load images and detect the rings using the model we just trained. In the notebook, we will also plot them nice and pretty. However, to prevent a ton of images popping up when processing a large number of images, this option is defaulted to not occur.\n",
    "\n",
    "The first cell is a function to plot the images with boxes around the rings, and also to crop those boxes and save them as tif files.\n",
    "\n",
    "The second cell takes your input for images, model, and output folder, and then runs the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a number of photos with ground truth and predictions\n",
    "def plot_predicted(imageDirectory, outputDirectory, model, cfg, plot=False):\n",
    "    # load image and mask\n",
    "    for i in listdir(imageDirectory):\n",
    "        if i.endswith('.tif'):\n",
    "            image_number = listdir(imageDirectory).index(i)\n",
    "            # load the image and mask\n",
    "            \n",
    "            imgPath = os.path.join(imageDirectory, i)\n",
    "            image = skimage.io.imread(imgPath)\n",
    "            #image = SeptinDataset.load_Septin(imgPath)\n",
    "            outPath = os.path.join(outputDirectory, i)\n",
    "            # If grayscale. Convert to RGB for consistency.\n",
    "            if image.ndim != 3:\n",
    "                image = skimage.color.gray2rgb(image)\n",
    "            # If has an alpha channel, remove it for consistency\n",
    "            if image.shape[-1] == 4:\n",
    "                image = image[..., :3]\n",
    "            #mask, _ = SeptinDataset.load_mask(i)\n",
    "            # convert pixel values (e.g. center)\n",
    "            scaled_image = mold_image(image, cfg)\n",
    "            # convert image into one sample\n",
    "            sample = expand_dims(scaled_image, 0)\n",
    "            # make prediction\n",
    "            yhat = model.detect(sample, verbose=0)[0]\n",
    "            # define subplot\n",
    "            if plot:\n",
    "                pyplot.imshow(image)\n",
    "\n",
    "                mask = yhat['masks']\n",
    "                for j in range(mask.shape[2]):\n",
    "                    pyplot.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n",
    "                    pyplot.title('Predicted Mask')\n",
    "\n",
    "                pyplot.title('Predicted')\n",
    "                ax = pyplot.gca()\n",
    "            # plot each box\n",
    "            n = 1\n",
    "            print(\"Looking at image\", i ,\"...\")\n",
    "            for box in yhat['rois']:\n",
    "                # get coordinates\n",
    "                y1, x1, y2, x2 = box\n",
    "                # increase box size\n",
    "                x1 = x1 - 10\n",
    "                y1 = y1 - 10\n",
    "                y2 = y2 + 10\n",
    "                x2 = x2 + 10\n",
    "                # calculate width and height of the box\n",
    "                width, height = x2 - x1, y2 - y1\n",
    "                # create the shape\n",
    "                rect = Rectangle((x1, y1), width, height, fill=False, color='red')\n",
    "                # draw the box\n",
    "                if plot:\n",
    "                    ax.add_patch(rect)\n",
    "                # Cut the rois from each image\n",
    "                # take output directory as user input in seperate script\n",
    "                img_crop = image[y1:y2,x1:x2]\n",
    "                # pad to 100x100\n",
    "                h, w, d = img_crop.shape\n",
    "                if h < 120 and w < 120:\n",
    "                    dh = (120-h)//2\n",
    "                    dw = (120-w)//2\n",
    "                    img_crop = pad(img_crop, ((dh,0),(dw,0),(0,0)), 'constant')\n",
    "                    h, w, d = img_crop.shape\n",
    "                    img_crop = pad(img_crop,((0,120-h),(0,120-w), (0,0)),'constant')\n",
    "                else:\n",
    "                    pass\n",
    "                if img_crop.size != 0 and np.mean(img_crop) != 0:\n",
    "                    skimage.io.imsave(outPath+str(n)+'.tif',img_crop, check_contrast = False)\n",
    "                    \n",
    "                n = n + 1\n",
    "            # show the figure\n",
    "            if plot:\n",
    "                pyplot.show()\n",
    "            print('Rings cropped: ' , n-1)\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0904 09:47:47.059910 18548 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0904 09:47:47.085911 18548 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0904 09:47:47.090912 18548 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0904 09:47:47.124913 18548 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1919: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0904 09:47:47.128914 18548 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0904 09:47:50.946132 18548 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "W0904 09:47:51.560167 18548 deprecation_wrapper.py:119] From C:\\Users\\Braedyn Au\\Desktop\\newmaskrcnn\\Mask_RCNN\\mrcnn\\model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0904 09:47:51.572168 18548 deprecation.py:323] From C:\\Users\\Braedyn Au\\Desktop\\newmaskrcnn\\Mask_RCNN\\mrcnn\\model.py:399: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0904 09:47:51.580168 18548 deprecation.py:506] From C:\\Users\\Braedyn Au\\Desktop\\newmaskrcnn\\Mask_RCNN\\mrcnn\\model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "W0904 09:47:52.088197 18548 deprecation_wrapper.py:119] From C:\\Users\\Braedyn Au\\Desktop\\newmaskrcnn\\Mask_RCNN\\mrcnn\\model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
      "\n",
      "W0904 09:47:52.094198 18548 deprecation_wrapper.py:119] From C:\\Users\\Braedyn Au\\Desktop\\newmaskrcnn\\Mask_RCNN\\mrcnn\\model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n",
      "W0904 09:47:52.219205 18548 deprecation.py:323] From C:\\Users\\Braedyn Au\\Desktop\\newmaskrcnn\\Mask_RCNN\\mrcnn\\model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-starting from epoch 8\n",
      "Looking at image 20190822_S2aS5b-g_3-15.tif ...\n",
      "Rings cropped:  9\n",
      "Looking at image 20190822_S2aS5b-g_3-16.tif ...\n",
      "Rings cropped:  2\n",
      "Looking at image 20190822_S2aS5bS2c-g_1-11.tif ...\n",
      "Rings cropped:  2\n",
      "Looking at image 20190822_S2aS5bS2c-g_1-12.tif ...\n",
      "Rings cropped:  1\n",
      "Looking at image 20190822_S2aS5bS2c-g_1-5.tif ...\n",
      "Rings cropped:  0\n",
      "Looking at image 20190822_S2aS5bS2c-g_1-6.tif ...\n",
      "Rings cropped:  1\n",
      "Looking at image 20190822_S2aS5bS2c-g_2-1.tif ...\n",
      "Rings cropped:  2\n",
      "Looking at image 20190822_S2aS5bS2c-g_2-13.tif ...\n",
      "Rings cropped:  0\n",
      "Looking at image 20190822_S2aS5bS2c-g_2-14.tif ...\n",
      "Rings cropped:  8\n",
      "Looking at image 20190822_S2aS5bS2c-g_2-2.tif ...\n",
      "Rings cropped:  4\n",
      "Looking at image 20190822_S2aS5bS2c-g_2-7.tif ...\n",
      "Rings cropped:  7\n",
      "Looking at image 20190822_S2aS5bS2c-g_2-8.tif ...\n",
      "Rings cropped:  3\n",
      "Looking at image 20190822_S2aS5bS2c-g_3-10.tif ...\n",
      "Rings cropped:  3\n",
      "Looking at image 20190822_S2aS5bS2c-g_3-15.tif ...\n",
      "Rings cropped:  0\n",
      "Looking at image 20190822_S2aS5bS2c-g_3-3.tif ...\n",
      "Rings cropped:  1\n",
      "Looking at image 20190822_S2aS5bS2c-g_4-11.tif ...\n",
      "Rings cropped:  3\n",
      "Looking at image 20190822_S2aS5bS2c-g_4-12.tif ...\n",
      "Rings cropped:  3\n",
      "Looking at image 20190822_S2aS5bS2c-g_4-5.tif ...\n",
      "Rings cropped:  1\n",
      "Looking at image 20190822_S2aS5bS2c-g_4-6.tif ...\n",
      "Rings cropped:  1\n",
      "Looking at image 20190822_S2aS5bS2c-g_5-1.tif ...\n",
      "Rings cropped:  1\n",
      "Looking at image 20190822_S2aS5bS2c-g_5-13.tif ...\n",
      "Rings cropped:  4\n",
      "Looking at image 20190822_S2aS5bS2c-g_5-14.tif ...\n",
      "Rings cropped:  2\n",
      "Looking at image 20190822_S2aS5bS2c-g_5-2.tif ...\n",
      "Rings cropped:  1\n",
      "Looking at image 20190822_S2aS5bS2c-g_5-7.tif ...\n",
      "Rings cropped:  0\n",
      "Looking at image 20190822_S2aS5bS2c-g_5-8.tif ...\n",
      "Rings cropped:  6\n",
      "Looking at image 20190822_S5aS2b-g_1-10.tif ...\n",
      "Rings cropped:  2\n",
      "Looking at image 20190822_S5aS2b-g_1-15.tif ...\n",
      "Rings cropped:  2\n",
      "Looking at image 20190822_S5aS2b-g_1-16.tif ...\n",
      "Rings cropped:  1\n",
      "Looking at image 20190822_S5aS2b-g_1-3.tif ...\n",
      "Rings cropped:  1\n",
      "Looking at image 20190822_S5aS2b-g_1-9.tif ...\n",
      "Rings cropped:  3\n",
      "Looking at image 20190822_S5aS2b-g_2-11.tif ...\n",
      "Rings cropped:  0\n",
      "Looking at image 20190822_S5aS2b-g_2-12.tif ...\n",
      "Rings cropped:  3\n",
      "Looking at image 20190822_S5aS2b-g_2-5.tif ...\n",
      "Rings cropped:  2\n",
      "Looking at image 20190822_S5aS2b-g_2-6.tif ...\n",
      "Rings cropped:  3\n",
      "Looking at image 20190822_S5aS2b-g_3-2.tif ...\n",
      "Rings cropped:  0\n",
      "Looking at image 20190822_S5aS2b-g_3-7.tif ...\n",
      "Rings cropped:  3\n",
      "Looking at image 20190822_S5aS2b-g_3-8.tif ...\n",
      "Rings cropped:  0\n"
     ]
    }
   ],
   "source": [
    "# load the images\n",
    "messagebox.showinfo(\"Images\", \"Load the folder containing images\")\n",
    "imageDirectory = filedialog.askdirectory()\n",
    "#train_set.load_dataset('Ring', is_train=True)\n",
    "#train_set.prepare()\n",
    "#print('Train: %d' % len(train_set.image_ids))\n",
    "# create config\n",
    "cfg = PredictionConfig()\n",
    "# define the model\n",
    "model = MaskRCNN(mode='inference', model_dir='./', config=cfg)\n",
    "# load model weights with tkinter\n",
    "messagebox.showinfo(\"Model\", \"Load model found in septin_cfg... folder\")\n",
    "model_path = filedialog.askopenfilename() \n",
    "model.load_weights(model_path, by_name=True)\n",
    "messagebox.showinfo(\"Output\", \"Choose output folder\")\n",
    "outputDirectory = filedialog.askdirectory()\n",
    "\n",
    "# plot predictions for images\n",
    "plot_predicted(imageDirectory, outputDirectory, model, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
